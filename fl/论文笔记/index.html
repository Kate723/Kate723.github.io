
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.3.3">
    
    
      
        <title>5 主要方法 - 纪安的笔记本</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.5143246d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.3f5d1f46.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#5" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="纪安的笔记本" class="md-header__button md-logo" aria-label="纪安的笔记本" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            纪安的笔记本
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              5 主要方法
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="纪安的笔记本" class="md-nav__button md-logo" aria-label="纪安的笔记本" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    纪安的笔记本
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        主页
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          课程项目
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="课程项目" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          课程项目
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        隐私保护
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../cv/" class="md-nav__link">
        模式识别
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ir/" class="md-nav__link">
        信息检索
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          技术学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="技术学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          技术学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/" class="md-nav__link">
        linux学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../docker/" class="md-nav__link">
        Docker学习
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#51" class="md-nav__link">
    5.1 数据方法
  </a>
  
    <nav class="md-nav" aria-label="5.1 数据方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#511" class="md-nav__link">
    5.1.1 共享数据
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#512" class="md-nav__link">
    5.1.2 数据增强
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    5.2 算法方法
  </a>
  
    <nav class="md-nav" aria-label="5.2 算法方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#521" class="md-nav__link">
    5.2.1 本地微调
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#522" class="md-nav__link">
    5.2.2 个性化层
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#523" class="md-nav__link">
    ※5.2.3 多任务学习
  </a>
  
    <nav class="md-nav" aria-label="※5.2.3 多任务学习">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    引文
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#524" class="md-nav__link">
    ※5.2.4 知识蒸馏
  </a>
  
    <nav class="md-nav" aria-label="※5.2.4 知识蒸馏">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    引文
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#525" class="md-nav__link">
    5.2.5 持续学习
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#526" class="md-nav__link">
    5.2.6 结构适应
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="5">5 主要方法<a class="headerlink" href="#5" title="Permanent link">&para;</a></h1>
<p>non-IID数据，尤其是标签分布偏斜类型，将会导致参数模型特别是水平FL的严重问题。但现有的算法不能解决这种问题，尤其是在应用复杂模型，比如说神经网络的情况下。现在的解决方法可以分为三个方面。此外，以下提到的FL均默认为水平FL，算法为算法1描述的FedAvg算法，模型为神经网络。</p>
<h2 id="51">5.1 数据方法<a class="headerlink" href="#51" title="Permanent link">&para;</a></h2>
<p>直觉上，FL表现的恶化是和数据分布相关的，因此我们寻求方法来改善数据分布。</p>
<h3 id="511">5.1.1 共享数据<a class="headerlink" href="#511" title="Permanent link">&para;</a></h3>
<h3 id="512">5.1.2 数据增强<a class="headerlink" href="#512" title="Permanent link">&para;</a></h3>
<h2 id="52">5.2 算法方法<a class="headerlink" href="#52" title="Permanent link">&para;</a></h2>
<p>本地模型可能会在模型分享的过程中遭到损坏，或是由于数据碎片的偏移无法合并。此外，传统的loss函数的输出是适用于所有节点，因此，每个节点的准确度可能会降低。节点需求不同的情况也很难满足。</p>
<p>可以采用个性化的方式去解决这些问题，按照本地任务来调整模型。</p>
<h3 id="521">5.2.1 本地微调<a class="headerlink" href="#521" title="Permanent link">&para;</a></h3>
<h3 id="522">5.2.2 个性化层<a class="headerlink" href="#522" title="Permanent link">&para;</a></h3>
<h3 id="523">※5.2.3 多任务学习<a class="headerlink" href="#523" title="Permanent link">&para;</a></h3>
<p>解决个性化问题的一个替代方案是把它当成多任务学习问题【12】。MOCHA是一个联邦多任务学习的代表框架，它考虑了FL的交流代价、掉队以及容错问题【122】。由于使用了原始对偶算法优化方法，MOCHA为每个节点分别生成了相关的模型，这使它不适合解决非凸优化问题。Corinzia提出了一个联邦多任务学习框架VIRTUAL，使用了贝叶斯网络和近似变分推断，它可以处理非凸优化问题。这个方法能很好的处理non-IID数据，但当节点数量众多时因为顺序微调会有收敛困难问题。【21】为了缓解不协调数据分布引起的表现恶化，Sattler提出了一个非凸优化FMTL框架为本地信息分组，称为聚集FL（CFL）。【111】它在以余弦相似度的节点群分布上有着很好的计算效率指标。但由于对数据相似性的依赖，CFL或许会威胁到数据安全。</p>
<h4 id="_1">引文<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h4>
<ul>
<li>[12]Caruana, R., 1997. Multitask learning. Machine learning 28, 41–75.</li>
</ul>
<p>本文回顾了 MTL 的先前工作，提出了新的证据，证明反向传播网络中的 MTL 在不需要监督信号的情况下发现任务相关性，并提出了具有 k-最近邻（k-nearest neighbor）和内核回归（kernel regression）的 MTL 的新结果。在本文中，我们展示了三个领域的多任务学习。我们解释了多任务学习的工作原理，并表明在实际领域中有很多多任务学习的机会。我们使用基于案例的方法（如 k 最近邻和核回归）提出了多任务学习的算法和结果，并勾勒出决策树中多任务学习的算法。</p>
<ul>
<li>[122] Smith, V., Chiang, C.K., Sanjabi, M., Talwalkar, A.S., 2017. Federated multi-task learning, in: Advances in Neural Information Processing Systems, pp. 4424–4434.</li>
</ul>
<p>联邦学习在通过分布式设备网络训练机器学习模型方面带来了新的统计和系统挑战。在这项工作中，我们展示了多任务学习自然适合处理这种设置的统计挑战，并提出了一种新颖的系统感知优化方法 MOCHA，它对实际系统问题具有鲁棒性。我们的方法和理论首次考虑了分布式多任务学习的高通信成本、落后者和容错性问题。与联合设置中的替代方法相比，所得到的方法实现了显着的加速，正如我们通过对真实世界联合数据集的模拟所证明的那样。</p>
<ul>
<li>[21] Corinzia, L., Beuret, A., Buhmann, J.M., 2019. Variational federated multi-task learning. arXiv preprint arXiv:1906.06268 .</li>
</ul>
<p>在联邦学习中，中央服务器在大规模分布式设备网络上协调单个模型的训练。此设置可以自然地扩展到多任务学习框架，以处理通常在设备之间显示出强大统计异质性的真实世界联合数据集。尽管联合多任务学习被证明是现实世界数据集的有效范式，但它仅应用于凸模型。在这项工作中，我们介绍了 VIRTUAL，这是一种用于一般非凸模型的联合多任务学习的算法。在 VIRTUAL 中，服务器和客户端的联合网络被视为星形贝叶斯网络，并使用近似变分推理在网络上进行学习。我们表明这种方法在真实世界的联合数据集上是有效的，</p>
<ul>
<li>[111] Sattler, F., Müller, K.R., Samek, W., 2020. Clustered federated learning: Model-agnostic distributed multitask optimization under privacy constraints. IEEE Transactions on Neural Networks and Learning Systems .</li>
</ul>
<p>联邦学习（FL）是目前最广泛采用的框架，用于在隐私约束下（深度）机器学习模型的协作训练。尽管它很受欢迎，但已经观察到如果本地客户端的数据分布不同，FL 会产生次优结果。为了解决这个问题，我们提出了集群 FL (CFL)，这是一种新的联合多任务学习 (FMTL) 框架，它利用 FL 损失面的几何特性将客户端群体分组为具有联合可训练数据分布的集群。与现有的 FMTL 方法相比，CFL 不需要对 FL 通信协议进行任何修改，适用于一般的非凸目标（特别是深度神经网络），不需要先验地知道簇的数量，并为聚类质量提供了强有力的数学保证。CFL 足够灵活，可以处理随时间变化的客户群，并且可以以保护隐私的方式实施。由于聚类仅在 FL 收敛到固定点后执行，因此 CFL 可以被视为一种后处理方法，通过允许客户端获得更专业的模型，它始终可以实现比传统 FL 更高或相等的性能。我们在常用 FL 数据集的深度卷积和循环神经网络实验中验证了我们的理论分析。CFL 可以被视为一种后处理方法，通过允许客户获得更专业的模型，它始终可以实现比传统 FL 更高或相等的性能。我们在常用 FL 数据集的深度卷积和循环神经网络实验中验证了我们的理论分析。CFL 可以被视为一种后处理方法，通过允许客户获得更专业的模型，它始终可以实现比传统 FL 更高或相等的性能。我们在常用 FL 数据集的深度卷积和循环神经网络实验中验证了我们的理论分析。</p>
<h3 id="524">※5.2.4 知识蒸馏<a class="headerlink" href="#524" title="Permanent link">&para;</a></h3>
<p>【9，50，41】，将信息由大的模型转移到小的模型的概念首先由【9】提出，而后被以知识蒸馏的名称推广。FL的主要动机即将知识从节点向特定节点传输来提高它在未知的多样数据下的表现。总而言之，有两种方式，联邦迁移学习（federated transfer learning）和领域自适应（domain adaption）。</p>
<p>**迁移学习**在联邦知识蒸馏中至关重要。在【132】中，作者用不同超参数训练了一个单词预测模型以确保它可以推广到新的移动设备。liu专注在去中心化的数据碎片下构建安全模型，提出了一个FTL框架，框架利用了同态加密【36】和密钥分享【14】作为协议【89】。lin【86】利用了集成蒸馏策略以稳定的融合多个模型，同时蒸馏模型降低了数据泄露风险和计算代价。A4是算法总结。</p>
<p>在算法的8-10行，可以发现无标签数据或人工汇总样本被用来辅助所有参与的节点进行知识提取，这个方法可以应用于同质和异质的设定，尽管使用无标签数据可能导致计算成本的增加。相似的，chang提出了一个通过上传学到的特征替代本地模型来实现本地个性化的合作鲁棒性学习策略，Cronus【13】。Li提出了Def-KT（通过互迁移知识去中心化FL），节点不通过云服务器直接交换数据【75】。作者提出FedAvg表现的退化可能是因为只转移模型的参数，Def-KT的重点是通过利用MKT（mutual knowledge transfer）的优势来消除标签偏移的影响【163】。具体来说，在每个轮次，一个选定节点子集首先在本地训练模型，然后将改进后的模型传递给第二个节点子集。第二节点子集的节点能够基于自己的和训练好的模型做出两个预测，这两个预测将作为虚拟标签同时更新本地和收到的模型。</p>
<p>**领域自适应**强调消除节点间数据碎片的差距。FADA（federated adversarial domain adaptation）算法在【105】提出，利用对抗适应来解决FL中域的转变（shift）。提出FedMD算法使得节点能够利用本地数据训练独有的模型【76】，核心是从节点共享的公共数据库传输知识。例如利用公共数据库训练模型之后利用本地数据继续训练。</p>
<h4 id="_2">引文<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<ul>
<li>[9] Bucilua, C., Caruana, R., Niculescu-Mizil, A., 2006. Model compression, in: Proceedings of the 12<sup>th</sup> ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 535–541.</li>
</ul>
<p>通常，性能最好的监督学习模型是由成百上千个基础分类器组成的集合。不幸的是，存储这么多分类器所需的空间，以及在运行时执行它们所需的时间，禁止它们在测试集很大的应用程序中使用（例如谷歌），其中存储空间非常宝贵（例如 PDA），以及计算能力有限的地方（例如助听器）。我们提出了一种将大型复杂集成“压缩”为更小、更快的模型的方法，通常不会显着降低性能。</p>
<ul>
<li>[50] Hinton, G., Vinyals, O., Dean, J., 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 .</li>
</ul>
<p>提高几乎所有机器学习算法性能的一种非常简单的方法是在相同的数据上训练许多不同的模型，然后对它们的预测进行平均。不幸的是，使用整个模型集合进行预测很麻烦，而且计算成本可能太高而无法部署到大量用户，尤其是在单个模型是大型神经网络的情况下。Caruana 和他的合作者已经表明，可以将集成中的知识压缩成一个更容易部署的模型，我们使用不同的压缩技术进一步开发了这种方法。我们在 MNIST 上取得了一些令人惊讶的结果，并且表明我们可以通过将模型集合中的知识提炼到单个模型中来显着改善大量使用的商业系统的声学模型。我们还介绍了一种由一个或多个完整模型和许多专业模型组成的新型集成，这些模型学习区分完整模型混淆的细粒度类。与专家的混合不同，这些专家模型可以快速并行地进行训练。</p>
<ul>
<li><a href="https://link.springer.com/article/10.1007/s11263-021-01453-z">[41] Gou, J., Yu, B., Maybank, S.J., Tao, D., 2021. Knowledge distillation: A survey. International Journal of Computer Vision , 1–31.</a></li>
</ul>
<p>近年来，深度神经网络在工业界和学术界都取得了成功，尤其是在计算机视觉任务方面。深度学习的巨大成功主要归功于它在编码大规模数据和操纵数十亿模型参数方面的可扩展性。然而，将这些繁琐的深度模型部署在资源有限的设备上是一个挑战，例如移动电话和嵌入式设备，不仅因为计算复杂度高，而且存储要求大。为此，已经开发了多种模型压缩和加速技术。作为模型压缩和加速的代表类型，知识蒸馏有效地从大的教师模型中学习到小的学生模型。它迅速受到社会各界的关注。本文从知识类别、训练方案、师生架构、蒸馏算法、性能对比和应用等方面对知识蒸馏进行了全面的综述。此外，简要回顾了知识提炼中的挑战，并讨论和转发了对未来研究的评论。</p>
<ul>
<li>[132] Wang, K.,Mathews, R., Kiddon, C., Eichner, H., Beaufays, F., Ramage, D., 2019a. Federated evaluation of on-device personalization. arXiv preprint arXiv:1910.10252 .</li>
</ul>
<p>联邦学习是一种分布式的设备端计算框架，可以在不将敏感用户数据导出到服务器的情况下训练全局模型。在这项工作中，我们描述了扩展联邦框架以评估全局模型个性化策略的方法。我们提供了分析个性化效果的工具，并评估个性化产生理想模型的条件。我们报告了我们为拥有数千万用户的智能手机的虚拟键盘个性化语言模型的实验。我们表明，很大一部分用户受益于个性化。</p>
<ul>
<li>
<p>[36] Gentry, C., et al., 2009. A fully homomorphic encryption scheme. volume 20. Stanford university Stanford.</p>
</li>
<li>
<p>[14] Chang, W.T., Tandon, R., 2018. On the capacity of secure distributed matrix multiplication, in: 2018 IEEE Global Communications Conference
  (GLOBECOM), IEEE. pp. 1–6.</p>
</li>
</ul>
<p>矩阵乘法是各种工程应用中的关键运算之一。将大规模矩阵乘法任务外包给多个分布式服务器或云对于加速计算是可取的。但是，当这些服务器不可信时，安全性就会成为一个问题。在本文中，我们研究了来自分布式不可信服务器的安全分布式矩阵乘法问题。这个问题属于安全函数计算的范畴，在密码学界受到了极大的关注。然而，表征信息理论上安全矩阵乘法的基本限制仍然是一个悬而未决的问题。我们专注于信息理论上安全的分布式矩阵乘法，目标是表征最小的通信开销。安全矩阵乘法的容量定义为所需信息与从 N 个分布式服务器接收的总通信量的最大可能比值。特别地，我们研究了以下两个模型，其中我们想要乘以两个矩阵 A ∈ \mathbbF m×n 和 B ∈ \mathbbF n×p ：(a) 单边安全矩阵乘法与 l 个共谋服务器，其中 B 是所有服务器都可用的公共矩阵，A 是私有矩阵。(b) 具有 l 个共谋服务器的完全安全的矩阵乘法，其中 A 和 B 都是私有矩阵。目标是在任何 l 个服务器可以串通时安全地乘以 A 和 B。对于模型 (a)，我们 通过提供安全矩阵乘法方案和匹配逆来描述容量为锥边 (l) = (Nl)/N。对于模型（b），我们提出了一种新的容量下限方案，即 Cfuly ≥ (√Nl) 2 /(√N-l+l) 2 。</p>
<ul>
<li>[89] Liu, Y., Kang, Y., Xing, C., Chen, T., Yang, Q., 2020b. A secure federated transfer learning framework. IEEE Intelligent Systems 35, 70–82.</li>
</ul>
<p>机器学习依赖于大量数据的可用性进行训练。然而，在现实中，数据大多分散在不同的组织中，由于许多法律和实践限制，无法轻松集成。为了解决机器学习领域的这一重要挑战，我们引入了一种称为联邦迁移学习 (FTL) 的新技术和框架，以改进数据联邦下的统计建模。FTL 允许在不损害用户隐私的情况下共享知识，并允许在数据联合中跨域传输补充知识，从而使目标域一方能够通过利用来自源域的丰富标签来构建灵活有效的模型。该框架需要对现有模型结构进行最少的修改，并提供与非隐私保护转移学习相同的准确性水平。它灵活，可以有效适应各种安全的多方机器学习任务。</p>
<ul>
<li>[86] Lin, T., Kong, L., Stich, S.U., Jaggi, M., 2020. Ensemble distillation for robust model fusion in federated learning. 34<sup>th</sup> Conference on Neural Information Processing Systems (NeurIPS 2020) .</li>
</ul>
<p>联合学习 (FL) 是一种机器学习设置，其中许多设备协作训练机器学习模型，同时保持训练数据分散。在大多数当前的训练方案中，中心模型是通过对服务器模型的参数和来自客户端的更新参数进行平均来细化的。然而，只有当所有模型具有相同的结构和大小时，才能直接平均模型参数，这在许多情况下可能是一个限制性约束。
  在这项工作中，我们研究了更强大、更灵活的 FL 聚合方案。具体来说，我们提出了用于模型融合的集成蒸馏，即通过客户端模型输出的未标记数据来训练中央分类器。这种知识提炼技术在与基线 FL 算法相同的程度上减轻了隐私风险和成本，但允许在异构客户端模型上灵活聚合，这些模型可以在例如大小、数值精度或结构方面不同。我们在各种 CV/NLP 数据集（CIFAR-10/100、ImageNet、AG News、SST2）和设置（异构模型/数据）的大量实证实验中表明，可以更快地训练服务器模型，需要的通信轮次比任何现有的 FL 技术。</p>
<ul>
<li>[13] Chang, H., Shejwalkar, V., Shokri, R., Houmansadr, A., 2019. Cronus: Robust and heterogeneous collaborative learning with black-box knowledge transfer. arXiv preprint arXiv:1912.11279 .</li>
</ul>
<p>协作（联合）学习使多方能够在不共享其私有数据的情况下训练模型，而是通过重复共享其本地模型的参数。尽管有其优势，但这种方法除了仅限于具有同构架构的模型之外，还有许多已知的隐私和安全弱点以及性能开销。共享参数会泄露大量有关本地（并且可能是私有的）数据集的信息。此外，联邦学习非常容易受到中毒攻击，其中一些参与者可以对抗性地影响聚合参数。具有高维参数向量的大型模型特别容易受到隐私和安全攻击：联邦学习中的维数诅咒。我们认为共享参数是协作学习中最简单的信息交换方式，因为它们将模型的所有内部状态开放给推理攻击，并通过隐身投毒攻击最大化模型的延展性。我们提出了 Cronus，一个强大的协作机器学习框架。设计 Cronus 背后的简单而有效的想法是通过他们的黑盒本地模型之间的强大知识转移来控制、统一并显着减少各方之间交换信息的维度。我们针对中毒攻击评估了所有现有的联邦学习算法，并表明 Cronus 是唯一安全的方法，因为它具有严格的鲁棒性保证。将局部模型视为黑盒，减少通过模型的信息泄漏，并使我们能够使用现有的隐私保护算法，通过模型的输出（预测）降低信息泄漏的风险。与联邦学习相比，Cronus 的样本复杂性也显着降低，联邦学习的安全性与参与者数量无关。</p>
<ul>
<li>[75] Li, C., Li, G., Varshney, P.K., 2020a. Decentralized federated learning via mutual knowledge transfer. arXiv preprint arXiv:2012.13063 .</li>
</ul>
<p>在本文中，我们研究了物联网 (IoT) 系统中分散联邦学习 (DFL) 的问题，其中许多 IoT 客户端为一项共同任务共同训练模型，而无需在没有中央服务器的情况下共享其私人训练数据. 大多数现有的 DFL 方案由两个交替的步骤组成，即模型更新和模型平均。然而，直接平均模型参数以在本地客户端融合不同模型会受到客户端漂移的影响，尤其是当不同客户端的训练数据异构时。这导致收敛缓慢和学习性能下降。作为一种可能的解决方案，我们提出了通过相互知识转移 (Def-KT) 算法的分散联邦学习，其中本地客户端通过相互转移他们学到的知识来融合模型。</p>
<ul>
<li>[163] Zhang, Y., Xiang, T., Hospedales, T.M., Lu, H., 2018b. Deep mutual learning, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4320–4328.</li>
</ul>
<p>模型蒸馏是一种有效且广泛使用的技术，可将知识从教师网络转移到学生网络。典型的应用是从强大的大型网络或集成转移到小型网络，以满足低内存或快速执行的要求。在本文中，我们提出了一种深度相互学习 (DML) 策略。与模型蒸馏中静态预定义教师和学生之间的单向转移不同，使用 DML，一组学生在整个培训过程中协作学习并相互教学。我们的实验表明，各种网络架构受益于相互学习，并在类别和实例识别任务上取得了令人信服的结果。出奇，</p>
<ul>
<li>[105] Peng, X., Huang, Z., Zhu, Y., Saenko, K., 2019. Federated adversarial domain adaptation. arXiv preprint arXiv:1911.02054 .</li>
</ul>
<p>联邦学习提高了在分布式设备（如手机、物联网和可穿戴设备等）网络上执行机器学习的数据隐私和效率。 然而，由于域转移问题，使用联邦学习训练的模型仍然无法推广到新设备. 当源节点收集的标记数据与目标节点的未标记数据在统计上不同时，就会发生域转移。在这项工作中，我们提出了一种解决联邦域适应问题的原则性方法，旨在将不同节点之间学习的表示与目标节点的数据分布对齐。我们的方法将对抗性适应技术扩展到联合设置的约束。此外，我们设计了一种动态注意力机制并利用特征解开来增强知识转移。根据经验，我们对多个图像和文本分类任务进行了广泛的实验，并在无监督的联邦域适应设置下显示出有希望的结果。</p>
<ul>
<li>[76] Li, D., Wang, J., 2019. Fedmd: Heterogenous federated learning via model distillation. arXiv preprint arXiv:1910.03581 .</li>
</ul>
<p>联合学习可以创建强大的集中式模型，而不会影响多个参与者的数据隐私。虽然成功，但它没有包含每个参与者独立设计自己的模型的情况。由于知识产权问题以及任务和数据的异构性质，这是联邦学习在医疗保健和人工智能即服务等领域应用的普遍要求。在这项工作中，我们使用迁移学习和知识蒸馏来开发一个通用框架，当每个代理不仅拥有他们的私人数据，而且拥有独特设计的模型时，该框架可以实现联邦学习。我们在 MNIST/FEMNIST 数据集和 CIFAR10/CIFAR100 数据集上测试我们的框架，并观察所有参与模型的快速改进。有 10 位不同的参与者，</p>
<h3 id="525">5.2.5 持续学习<a class="headerlink" href="#525" title="Permanent link">&para;</a></h3>
<h3 id="526">5.2.6 结构适应<a class="headerlink" href="#526" title="Permanent link">&para;</a></h3>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        
          Made with
          <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
            Material for MkDocs
          </a>
        
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": [], "translations": {"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.8397ff9e.min.js", "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f89c2efe.min.js"></script>
      
    
  </body>
</html>